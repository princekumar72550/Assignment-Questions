{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180c3bb-b2e9-4176-bac2-3cbdfac76ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Explain the concept of precision and recall in the context of classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561f5e3-96bf-49a2-bd0a-d83cb58bcdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Precision:\n",
    "   - Precision measures the accuracy of positive predictions made by the model, specifically the proportion of true positive predictions out of all instances predicted as positive.\n",
    "   - Mathematically, precision is calculated as the ratio of true positive predictions to the sum of true positive and false positive predictions:\n",
    "     \\[ \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}} \\]\n",
    "   - Precision focuses on the quality of positive predictions, answering the question: \"Of all instances predicted as positive, how many were actually positive?\"\n",
    "   - A high precision indicates that the model makes positive predictions with high accuracy and has a low false positive rate. It reflects the model's ability to avoid false alarms or incorrectly labeling negative instances as positive.\n",
    "\n",
    "2. Recall (Sensitivity):\n",
    "   - Recall measures the completeness of positive predictions made by the model, specifically the proportion of true positive predictions out of all actual positive instances.\n",
    "   - Mathematically, recall is calculated as the ratio of true positive predictions to the sum of true positive and false negative predictions:\n",
    "     \\[ \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}} \\]\n",
    "   - Recall focuses on the ability of the model to capture all positive instances, answering the question: \"Of all actual positive instances, how many were correctly predicted by the model?\"\n",
    "   - A high recall indicates that the model can effectively identify positive instances and has a low false negative rate. It reflects the model's ability to avoid missing positive instances.\n",
    "\n",
    "In summary:\n",
    "- Precision emphasizes the accuracy of positive predictions, while recall emphasizes the completeness of positive predictions.\n",
    "- Precision is concerned with minimizing false positives, while recall is concerned with minimizing false negatives.\n",
    "- Depending on the specific requirements of the classification task and the associated costs of false positives and false negatives, you may need to prioritize precision, recall, or strike a balance between the two using techniques like threshold adjustment or utilizing metrics like the F1 score, which is the harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60975f7f-6007-46c0-9647-bd342c1a5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the F1 score and how is it calculated? How is it different from precision and recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d4746-1ca6-4fd1-820f-15bcd8b9d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "The F1 score is a single metric that combines precision and recall into a single value, providing a balance between the two metrics. \n",
    "It is particularly useful when you have an uneven class distribution or when false positives and false negatives have different\n",
    "consequences.\n",
    "\n",
    "The F1 score is calculated as the harmonic mean of precision and recall:\n",
    "\n",
    "\\[ F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\]\n",
    "\n",
    "Where:\n",
    "- Precision is the proportion of true positive predictions out of all instances predicted as positive.\n",
    "- Recall is the proportion of true positive predictions out of all actual positive instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956733a-39e7-4177-8036-81734419222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is ROC and AUC, and how are they used to evaluate the performance of classification models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5249063-cf8d-49d3-8710-7c84dd377e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "The ROC AUC score tells us how efficient the model is. The higher the AUC, the better the model's performance at distinguishing \n",
    "between the positive and negative classes. An AUC score of 1 means the classifier can perfectly distinguish between all the \n",
    "Positive and the Negative class points.\n",
    "\n",
    "ROC Curve:\n",
    "- The ROC curve is a graphical representation of the performance of a binary classification model across different threshold settings.\n",
    "- It plots the true positive rate (TPR), also known as sensitivity or recall, against the false positive rate (FPR), where:\n",
    "  - True Positive Rate (TPR) = TP / (TP + FN)\n",
    "  - False Positive Rate (FPR) = FP / (FP + TN)\n",
    "- The ROC curve illustrates the trade-off between the true positive rate (sensitivity) and the false positive rate (1 - specificity) at various threshold settings.\n",
    "- A diagonal line from (0,0) to (1,1) represents random guessing, while a curve above the diagonal indicates better-than-random performance.\n",
    "\n",
    "AUC (Area Under the ROC Curve):\n",
    "- AUC quantifies the overall performance of a classification model by calculating the area under the ROC curve.\n",
    "- AUC ranges from 0 to 1, where a higher AUC value indicates better model performance:\n",
    "  - AUC = 1: Perfect classifier (achieving a TPR of 1 while maintaining an FPR of 0)\n",
    "  - AUC = 0.5: Random guessing (the ROC curve follows the diagonal line)\n",
    "  - AUC < 0.5: Worse than random guessing (the ROC curve falls below the diagonal line)\n",
    "- AUC provides a single scalar value to compare the performance of different classifiers, regardless of the threshold setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a017a7dc-bdee-4df8-95d0-726ee078fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. How do you choose the best metric to evaluate the performance of a classification model?\n",
    "What is multiclass classification and how is it different from binary classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8fb25a-b455-4dbc-b019-597877ba1ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Nature of the Problem:\n",
    "   - Consider the nature of the problem you are trying to solve. Are false positives or false negatives more costly? Understanding the consequences of misclassifications in your application domain can help prioritize certain metrics over others.\n",
    "   - For example, in medical diagnostics, false negatives (missing positive cases) might be more critical than false positives (incorrectly identifying negative cases as positive), as missing a disease could have severe consequences.\n",
    "\n",
    "2. Class Imbalance:\n",
    "   - If the dataset is highly imbalanced, where one class is significantly more prevalent than the other, accuracy may not be a reliable metric. In such cases, metrics like precision, recall, F1 score, and AUC-ROC may provide more meaningful insights into model performance.\n",
    "   - Precision, recall, and F1 score are particularly useful for imbalanced datasets as they focus on the performance of the minority class.\n",
    "\n",
    "3. Threshold Sensitivity:\n",
    "   - Some metrics, such as accuracy, are not sensitive to changes in the classification threshold and may not adequately reflect the performance of the model, especially in scenarios where the threshold needs to be adjusted to meet specific requirements.\n",
    "   - Metrics like precision, recall, and F1 score provide insights into the trade-offs between true positives and false positives at different threshold settings.\n",
    "\n",
    "4. Model Interpretability:\n",
    "   - Consider the interpretability of the metric. While AUC-ROC provides a single scalar value summarizing the overall performance of the model, precision, recall, and F1 score offer more interpretable insights into the model's behavior, particularly with respect to different classes or threshold settings.\n",
    "\n",
    "5. Project Goals and Stakeholder Requirements:\n",
    "   - Ultimately, the choice of metric should align with the goals of the project and the requirements of stakeholders. Discuss with stakeholders to understand their priorities and preferences regarding model performance metrics.\n",
    "\n",
    "6. Cross-Validation and Robustness:\n",
    "   - Use cross-validation to evaluate model performance across multiple folds and ensure robustness of the chosen metric. Consider averaging the metric values across folds to obtain a more reliable estimate of model performance.\n",
    "\n",
    "7. Complementary Metrics:\n",
    "   - It's often beneficial to consider multiple metrics to gain a comprehensive understanding of model performance. For example, while precision and recall provide insights into different aspects of model performance, the F1 score combines them into a single metric that balances both precision and recall.\n",
    "\n",
    "Multiclass classification is the process of assigning entities with more than two classes. \n",
    "Each entity is assigned to one class without any overlap. An example of multiclass classification,\n",
    "using images of vegetables, where each image is either a carrot, tomato, or zucchini.\n",
    "\n",
    "Multiclass classification is a type of classification task where the goal is to classify instances into one of three or more classes or categories. Each instance in the dataset can belong to only one class. Examples of multiclass classification tasks include predicting the species of a flower (e.g., iris setosa, iris versicolor, iris virginica) based on its features, classifying handwritten digits into one of ten possible classes (0 through 9), or categorizing news articles into different topics (e.g., sports, politics, technology).\n",
    "\n",
    "In multiclass classification:\n",
    "- Each instance is assigned to one and only one class out of multiple possible classes.\n",
    "- The output of the model is a single predicted class label for each instance, chosen from a set of predefined classes.\n",
    "\n",
    "On the other hand, binary classification is a type of classification task where the goal is to classify instances into one of two possible classes or categories. Examples of binary classification tasks include spam email detection (spam or not spam), sentiment analysis (positive or negative sentiment), or medical diagnosis (disease present or not present).\n",
    "\n",
    "In binary classification:\n",
    "- Each instance is assigned to one of two possible classes: positive (often represented as class 1) or negative (often represented as class 0).\n",
    "- The output of the model is a single predicted class label for each instance, indicating whether it belongs to the positive class or the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdcd6e7-0525-4d9f-ac34-8e1d45ccee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Explain how logistic regression can be used for multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da58455-3081-4231-9698-3ac21706d0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic regression is a binary classification algorithm that is commonly used for tasks where the goal is to predict binary outcomes\n",
    "(e.g., whether an email is spam or not spam). However, logistic regression can also be extended to handle multiclass classification \n",
    "tasks through various techniques, such as the one-vs-rest (OvR) or one-vs-one (OvO) strategies.\n",
    "\n",
    "1. One-vs-Rest (OvR) Strategy:\n",
    "   - In the OvR strategy, also known as one-vs-all, a separate binary logistic regression model is trained for each class, treating that class as the positive class and all other classes as the negative class.\n",
    "   - For example, if you have \\( K \\) classes, you would train \\( K \\) binary logistic regression classifiers. Each classifier learns to distinguish instances of its corresponding class from instances of all other classes.\n",
    "   - During prediction, the class with the highest predicted probability from the \\( K \\) classifiers is selected as the final predicted class.\n",
    "   - OvR is straightforward to implement and works well for problems with a large number of classes.\n",
    "\n",
    "2. One-vs-One (OvO) Strategy:\n",
    "   - In the OvO strategy, also known as pairwise classification, a binary logistic regression model is trained for every pair of classes.\n",
    "   - For \\( K \\) classes, this results in \\( \\frac{{K \\times (K - 1)}}{2} \\) binary classifiers.\n",
    "   - During prediction, each classifier makes a prediction, and the class that receives the most \"votes\" (i.e., wins the most pairwise comparisons) is selected as the final predicted class.\n",
    "   - OvO can be computationally expensive for problems with a large number of classes but is more resilient to imbalanced class distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf3c9a-88f5-4856-a357-16bcb4b63b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Describe the steps involved in an end-to-end project for multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f98f78-5201-4257-82b7-957bf1cb604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "1. Problem Definition and Data Collection:\n",
    "   - Clearly define the problem you want to solve and the objectives of the classification task.\n",
    "   - Collect relevant data that contains features (inputs) and corresponding labels (class labels) for each instance. Ensure that the data is representative of the problem domain and adequately covers the classes you want to classify.\n",
    "\n",
    "2. Data Preprocessing and Exploration:\n",
    "   - Clean the data by handling missing values, removing duplicates, and addressing any inconsistencies or errors.\n",
    "   - Explore the dataset to gain insights into the distribution of classes, the relationship between features and labels, and potential patterns or correlations in the data.\n",
    "   - Perform feature engineering to extract or create relevant features that can improve model performance.\n",
    "\n",
    "3. Data Splitting:\n",
    "   - Split the dataset into training, validation, and test sets. The training set is used to train the model, the validation set is used to tune hyperparameters and evaluate model performance during training, and the test set is used to evaluate the final model's performance.\n",
    "\n",
    "4. Model Selection and Training:\n",
    "   - Choose an appropriate machine learning algorithm for multiclass classification, such as logistic regression, decision trees, random forests, support vector machines, or neural networks.\n",
    "   - Train the selected model using the training data. Tune hyperparameters using techniques like grid search or randomized search cross-validation to optimize model performance.\n",
    "   - Evaluate the model's performance on the validation set using relevant evaluation metrics (e.g., accuracy, precision, recall, F1 score, ROC-AUC).\n",
    "\n",
    "5. Model Evaluation and Fine-Tuning:\n",
    "   - Analyze the model's performance on the validation set and identify areas for improvement. Fine-tune the model by adjusting hyperparameters, feature selection, or model architecture.\n",
    "   - Iterate on the model development process, experimenting with different algorithms and strategies to improve performance.\n",
    "\n",
    "6. Final Model Evaluation:\n",
    "   - Evaluate the final trained model on the test set to assess its generalization performance on unseen data. Compute relevant evaluation metrics to measure the model's accuracy and robustness.\n",
    "\n",
    "7. Model Deployment:\n",
    "   - Once satisfied with the model's performance, deploy it into production for real-world use. This may involve integrating the model into an existing software system, creating an API for inference, or deploying it on a cloud platform.\n",
    "   - Monitor the model's performance in production and update it as needed to maintain accuracy and relevance over time.\n",
    "\n",
    "8. Documentation and Reporting:\n",
    "   - Document the entire project, including data sources, preprocessing steps, model selection criteria, training procedures, evaluation metrics, and deployment details.\n",
    "   - Prepare a comprehensive report or presentation summarizing the project findings, including insights gained, challenges faced, and recommendations for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a38a53c-ab07-4c86-8d40-c34aea6c2623",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. What is model deployment and why is it important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a016911-d75b-4299-9f76-a5e8f393046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model deployment in machine learning is the process of integrating your model into an existing production environment where it can\n",
    "take in an input and return an output. The goal is to make the predictions from your trained machine learning model available to\n",
    "others.\n",
    "\n",
    "\n",
    "1. Operationalizing Insights: Deploying a trained machine learning model allows organizations to operationalize the insights gained from data analysis and modeling. It enables the translation of predictive analytics into actionable decisions and outcomes.\n",
    "\n",
    "2. Value Generation: Deploying a model can lead to tangible value generation for businesses and organizations. By leveraging predictive models in production systems, companies can optimize processes, automate decision-making, improve efficiency, and drive revenue growth.\n",
    "\n",
    "3. Real-Time Decision-Making: Deployed models enable real-time or near-real-time decision-making, allowing organizations to respond quickly to changing conditions, make data-driven decisions, and capitalize on opportunities as they arise.\n",
    "\n",
    "4. Scalability: Model deployment allows organizations to scale predictive capabilities across the enterprise. Once deployed, a model can handle predictions for a large volume of data and serve multiple users or systems simultaneously, without manual intervention.\n",
    "\n",
    "5. Improved Customer Experience: Deployed models can enhance the customer experience by providing personalized recommendations, tailored services, and proactive interventions based on individual preferences and behavior.\n",
    "\n",
    "6. Continuous Learning and Improvement: Deploying a model in a production environment facilitates continuous learning and model improvement. By monitoring model performance, collecting feedback, and retraining the model with new data, organizations can ensure that the model remains accurate and relevant over time.\n",
    "\n",
    "7. Compliance and Governance: Deployed models are subject to regulatory compliance and governance requirements. Organizations must ensure that deployed models adhere to relevant regulations, standards, and ethical guidelines to mitigate risks and maintain trust.\n",
    "\n",
    "8. Return on Investment (ROI): Model deployment enables organizations to realize the return on investment (ROI) from their machine learning initiatives. By deploying models that deliver measurable business value, organizations can justify the resources and investment allocated to data science and machine learning projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a67a2-1041-4f0a-aca5-6b18aa338cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. Explain how multi-cloud platforms are used for model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0471f388-522b-4a37-811c-ed20999a01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Redundancy and High Availability: By deploying models across multiple cloud providers, organizations can achieve redundancy and high availability. If one cloud provider experiences downtime or service disruptions, models can continue to serve predictions from other cloud providers, ensuring uninterrupted service.\n",
    "\n",
    "2. Cost Optimization: Multi-cloud platforms allow organizations to take advantage of pricing variations and discounts offered by different cloud providers. Organizations can optimize costs by deploying models on cloud providers that offer the most cost-effective services for their specific requirements.\n",
    "\n",
    "3. Geographic Distribution: Multi-cloud platforms enable geographic distribution of models, allowing organizations to deploy models closer to their end-users or target regions. This reduces latency and improves performance by minimizing the distance data needs to travel between users and the deployed models.\n",
    "\n",
    "4. Vendor Lock-In Mitigation: Deploying models on multi-cloud platforms helps mitigate vendor lock-in, reducing dependency on a single cloud provider. Organizations can maintain flexibility and avoid being tied to a specific vendor's ecosystem, allowing them to switch providers or leverage multiple providers based on changing business needs.\n",
    "\n",
    "5. Hybrid Deployments: Organizations with specific data residency or compliance requirements can deploy models on multi-cloud platforms to maintain a hybrid deployment strategy. Certain models or workloads may need to run on-premises or in private cloud environments, while others can be deployed on public cloud providers. Multi-cloud platforms enable seamless integration and interoperability across different deployment environments.\n",
    "\n",
    "6. Disaster Recovery and Business Continuity: Multi-cloud platforms provide robust disaster recovery and business continuity capabilities. Organizations can replicate models and data across multiple cloud providers, ensuring data resilience and disaster recovery in case of unforeseen events or disasters.\n",
    "\n",
    "7. Cross-Cloud Data Sharing and Integration: Multi-cloud platforms facilitate cross-cloud data sharing and integration, allowing organizations to seamlessly transfer data between different cloud providers and applications. This enables interoperability and collaboration across diverse cloud ecosystems.\n",
    "\n",
    "8. Security and Compliance: Deploying models on multi-cloud platforms can enhance security and compliance posture. Organizations can leverage the security features and compliance certifications of different cloud providers to meet regulatory requirements and ensure data protection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96f350-769c-4d8b-b050-888efa84ad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. Discuss the benefits and challenges of deploying machine learning models in a multi-cloud\n",
    "environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff73a7b-e19f-40f2-9b97-dc4049b875b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Benefits:\n",
    "\n",
    "1. Flexibility and Choice: Multi-cloud environments provide organizations with the flexibility to choose from a variety of cloud service providers based on their specific requirements, such as cost, performance, features, and geographic location. This enables organizations to select the best-fit cloud providers for deploying their machine learning models, optimizing resource utilization, and meeting business objectives.\n",
    "\n",
    "2. Redundancy and High Availability: Deploying machine learning models across multiple cloud providers enhances redundancy and improves fault tolerance, ensuring high availability of services. If one cloud provider experiences downtime or service disruptions, models can continue to serve predictions from other cloud providers, minimizing the impact on users and maintaining business continuity.\n",
    "\n",
    "3. Scalability and Performance: Multi-cloud environments offer scalability and elasticity, allowing organizations to dynamically scale resources up or down based on workload demands. By distributing workloads across multiple cloud providers, organizations can improve performance, reduce latency, and enhance the user experience for applications that rely on machine learning models.\n",
    "\n",
    "4. Cost Optimization: Leveraging multiple cloud providers enables organizations to optimize costs by taking advantage of pricing variations, discounts, and promotions offered by different providers. Organizations can adopt a cost-effective strategy by selecting cloud providers that offer the most competitive pricing for their specific workloads, optimizing resource allocation, and minimizing overall expenditure.\n",
    "\n",
    "5. Vendor Lock-In Mitigation: Deploying machine learning models in a multi-cloud environment helps mitigate vendor lock-in, reducing dependency on a single cloud provider. Organizations can maintain flexibility and avoid being tied to a specific vendor's ecosystem, enabling them to switch providers, negotiate better terms, or leverage multiple providers based on changing business needs without significant disruption.\n",
    "\n",
    "Challenges:\n",
    "\n",
    "1. Complexity and Management Overhead: Managing machine learning models across multiple cloud providers introduces complexity and increases management overhead. Organizations need to navigate different interfaces, APIs, tools, and services offered by each cloud provider, requiring specialized expertise and resources to ensure effective deployment, monitoring, and maintenance of models.\n",
    "\n",
    "2. Data Integration and Interoperability: Integrating data across multiple cloud providers and ensuring interoperability between different services and environments can be challenging. Organizations need to establish robust data pipelines, data governance frameworks, and data synchronization mechanisms to facilitate seamless data sharing and integration across cloud environments while maintaining data consistency, integrity, and security.\n",
    "\n",
    "3. Security and Compliance Risks: Deploying machine learning models in a multi-cloud environment introduces security and compliance risks related to data protection, access control, identity management, and regulatory compliance. Organizations need to implement comprehensive security measures, encryption protocols, authentication mechanisms, and audit trails to safeguard sensitive data, mitigate security threats, and adhere to regulatory requirements across all cloud providers.\n",
    "\n",
    "4. Performance Variability: Performance variability and differences in service levels, network latency, and resource availability across different cloud providers can impact the performance and reliability of machine learning models. Organizations need to monitor and optimize performance, latency, and throughput metrics to ensure consistent and predictable performance across all cloud environments, especially for latency-sensitive applications and real-time inference workloads.\n",
    "\n",
    "5. Vendor-Specific Dependencies: While multi-cloud environments offer flexibility, organizations may inadvertently create vendor-specific dependencies, making it challenging to migrate workloads or switch providers in the future. Organizations need to carefully evaluate vendor lock-in risks, plan for exit strategies, and implement interoperability standards to minimize dependencies and maximize portability across cloud providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7cd65-72a6-484d-ac2e-2a2ff98bbd16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b0193-cc8b-4dcf-9058-d80785108c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c493792-22c3-4a85-a801-829760421bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f11ac1a-2cc5-4428-9d58-218bc9f2d78a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5422bc00-84c8-4b1e-a32a-56a03cf4a785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba4e0d5-a779-4893-9543-290c07f7eb05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae6132-e6fb-4a99-a3cd-8306580824fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce8baf4-ff37-4cd6-9d3b-c3abe2e7b2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d9b30-fad4-42b5-b776-ce5daf3b578c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e880c478-936c-42e3-b846-7708073a8de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807506e3-7b35-4fcd-8a4f-7e6d75e6e847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a8f4e-dcea-45b9-9938-b9031ff95d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
